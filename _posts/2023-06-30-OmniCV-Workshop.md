---
layout: post
title: D²iCE researchers co-organise the 4th Omnidirectional Computer Vision Workshop at CVPR'2023
thumbnail-img: /assets/img/blog/2023_omnicv_organisers.jpg
share-img: /assets/img/blog/2023_omnicv_organisers.jpg
tags: [Computer Vision, Machine Learning, Omnidirectional]
---
D²iCE researchers [Kaavya Rekanar](https://www.linkedin.com/in/kaavyarekanar) and [Ciarán Eising](https://www.linkedin.com/in/ciaraneising) co-organised the [4th Omnidirectional Computer Vision](https://sites.google.com/view/omnicv2023) (OmniCV) workshop took place on June 19th, 2023, as part of the prestigious [Conference on Computer Vision and Pattern Recognition (CVPR)](https://cvpr2023.thecvf.com/) in Vancouver, Canada. This workshop aimed to delve into the latest developments and applications of omnidirectional imaging, showcasing its potential to solve real-world problems across various fields. With an emphasis on maximizing a camera's field of view, the workshop aimed to bridge the gap between research and commercial products, encouraging the advancement of algorithms and applications in this exciting imaging modality.
Omnidirectional imaging has gained significant interest in recent years, driven by the desire to capture a comprehensive amount of content and context within a single image. The advent of fisheye cameras in modern vehicles and the availability of commodity omnidirectional cameras from companies like Ricoh and Insta360 have further fuelled the popularity of this imaging technique. 

![Attendees at OmniCV 2023](/assets/img/blog/2023_omnicv_crowd.jpg)

## Enabling Progress through Research and Technology

The Omnidirectional Computer Vision workshop sought to unite the foundational research supporting omnidirectional imaging with the development of commercial products leveraging this technology. By fostering collaboration and knowledge sharing, the workshop aimed to drive progress and inspire the creation of new algorithms and applications. The attendees had the opportunity to hear from esteemed speakers who shared their expertise and insights on various aspects of omnidirectional computer vision.

## Insightful Talks and Presentations

The workshop featured esteemed speakers who shared their expertise and insights on various aspects of omnidirectional computer vision. [Dr Robin Jenkin](https://www.google.com/url?q=https%3A%2F%2Fwww.linkedin.com%2Fin%2Frobinjenkin%2F&sa=D&sntz=1&usg=AOvVaw2LKWBlLL65aBBtowKcJIEx) from NVIDIA discussed the image quality of fisheye cameras, highlighting the challenges and advancements in capturing high-quality images with these wide-angle lenses. [Prof Wolfgang Förstner](https://www.google.com/url?q=https%3A%2F%2Fwww.ipb.uni-bonn.de%2Fpeople%2Fwolfgang-forstner%2F&sa=D&sntz=1&usg=AOvVaw3vWv1Diu4ihYjvCRdwSgIo) from Stuttgart University explored the techniques and algorithms used to recover geometry from omnidirectional camera systems. [Prof Jongwoo Lim](http://www.google.com/url?q=http%3A%2F%2Fcvlab.hanyang.ac.kr%2F~jwlim%2F&sa=D&sntz=1&usg=AOvVaw02_gLBXcK5LBcKe61w-6XT), a professor at Hanyang University and CEO of MultiplEYE Co., ltd., shared valuable insights on omnidirectional depth estimation and visual SLAM using multiple ultra-wide field-of-view cameras. [Prof Adrian Hilton](https://www.google.com/url?q=https%3A%2F%2Fwww.surrey.ac.uk%2Fpeople%2Fadrian-hilton&sa=D&sntz=1&usg=AOvVaw3JGx0vXqA-fYszKDvnGIdw) from the University of Surrey discussed audio-visual 360 scene analysis for acoustic modelling and augmentation. [Shubhankar Borse](https://www.linkedin.com/in/shubhankarborse/) from Qualcomm was a last-minute replacement for Jacob Roll, but gave an excellent talk on detection and segmentation in BEV using near-field surround cameras.

## Challenges to Foster Advancements

The workshop hosted three challenges to stimulate innovation in omnidirectional computer vision:
1.	[Multi-view 360 Layout Estimation Challenge](https://sites.google.com/view/omnicv2023/challenges/multi-view-layout-challenge?authuser=0):  Sponsored by the Taiwan AI Center of Excellence, participants were tasked with developing models that leverage multi-view consistency from an ego-motion of a 360-camera in real-world-based scenes. The challenge provided extensive datasets for training, testing, and algorithm development. 
2.	[Woodscape & Parallel Domain Challenge](https://sites.google.com/view/omnicv2023/challenges/woodscape-challenge): This challenge was hosted in collaboration with [Valeo](https://www.valeo.com/en/) and [Parallel Domain](https://paralleldomain.com/). It focused on training a single model capable of performing optimally on both real and synthetic data for moving object detection. Collaboration with Parallel Domain facilitated addressing the domain adaptation aspect of moving object detection tasks.
3.	[Omnidirectional Drone Challenge](https://sites.google.com/view/omnicv2023/challenges/omnidirectional-odometry-challenge?authuser=0): In collaboration with [Spleenlab](https://spleenlab.com/), the workshop organized a challenge centred around odometry and multi-sensor data analysis using drone data. Participants were provided with omnidirectional video footage captured by fisheye lenses, along with LiDAR and RTK GPS data. The challenge emphasized odometry and SLAM using omnidirectional input 360° in off-road scenarios.

![Attendees at OmniCV 2023](/assets/img/blog/2023_omnicv_organisers.jpg)
_Some of the organisers (Ashwanth Vishwanath, Enrique Solarte, Ciarán Eising, and Li Guan). The beautiful T-shirts were kindly donated by the workshop sponsor [Lero](https://lero.ie/)_

![Best paper award OmniCV 2023](/assets/img/blog/2023_omnicv_best_paper.jpg)
_Best paper award for "[Graph-CoVis: GNN-Based Multi-View Panorama Global Pose Estimation](https://openaccess.thecvf.com/content/CVPR2023W/OmniCV/html/Nejatishahidin_Graph-CoVis_GNN-Based_Multi-View_Panorama_Global_Pose_Estimation_CVPRW_2023_paper.html)", accepted by [Will Hutchcroft](https://www.linkedin.com/in/willhutchcroft/) (presented to Will by Shubhankar Borse, from the best paper award sponsors Qualcomm)_
